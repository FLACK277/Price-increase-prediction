{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce824be-9afe-4b2e-a084-982348a46020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (4349, 17)\n",
      "\n",
      "Column dtypes:\n",
      "stateFips                  int64\n",
      "area                       int64\n",
      "areaType                   int64\n",
      "period                     int64\n",
      "periodYear                 int64\n",
      "periodType                 int64\n",
      "periodTypeDescription     object\n",
      "cpi                      float64\n",
      "title                     object\n",
      "type                       int64\n",
      "source                     int64\n",
      "cpiSourceDescription      object\n",
      "percentChangeYear        float64\n",
      "percentChangeMonth       float64\n",
      "dataRegion                object\n",
      "areaName                  object\n",
      "areaDescription           object\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n",
      "   stateFips  area  areaType  period  periodYear  periodType  \\\n",
      "0          0     0         0       0        1913           1   \n",
      "1          0     0         0       0        1913           1   \n",
      "2          0     0         0       1        1913           3   \n",
      "3          0     0         0       1        1913           3   \n",
      "4          0     0         0       2        1913           3   \n",
      "\n",
      "  periodTypeDescription   cpi  \\\n",
      "0                Annual   9.9   \n",
      "1                Annual  10.0   \n",
      "2               Monthly   9.8   \n",
      "3               Monthly   9.9   \n",
      "4               Monthly   9.8   \n",
      "\n",
      "                                               title  type  source  \\\n",
      "0  CPI-U all items 1982-84=100, not seasonally ad...     1       1   \n",
      "1  CPI-W all items 1982-84=100, not seasonally ad...     3       1   \n",
      "2  CPI-U all items 1982-84=100, not seasonally ad...     1       1   \n",
      "3  CPI-W all items 1982-84=100, not seasonally ad...     3       1   \n",
      "4  CPI-U all items 1982-84=100, not seasonally ad...     1       1   \n",
      "\n",
      "                 cpiSourceDescription  percentChangeYear  percentChangeMonth  \\\n",
      "0  US DOL, Bureau of Labor Statistics                0.0                 0.0   \n",
      "1  US DOL, Bureau of Labor Statistics                0.0                 0.0   \n",
      "2  US DOL, Bureau of Labor Statistics                0.0                -1.0   \n",
      "3  US DOL, Bureau of Labor Statistics                0.0                -1.0   \n",
      "4  US DOL, Bureau of Labor Statistics                0.0                 0.0   \n",
      "\n",
      "  dataRegion       areaName                                    areaDescription  \n",
      "0         US  United States  The United States of America (commonly referre...  \n",
      "1         US  United States  The United States of America (commonly referre...  \n",
      "2         US  United States  The United States of America (commonly referre...  \n",
      "3         US  United States  The United States of America (commonly referre...  \n",
      "4         US  United States  The United States of America (commonly referre...  \n",
      "\n",
      "Missing values per column:\n",
      "stateFips                  0\n",
      "area                       0\n",
      "areaType                   0\n",
      "period                     0\n",
      "periodYear                 0\n",
      "periodType                 0\n",
      "periodTypeDescription      0\n",
      "cpi                        0\n",
      "title                      0\n",
      "type                       0\n",
      "source                     0\n",
      "cpiSourceDescription       0\n",
      "percentChangeYear          0\n",
      "percentChangeMonth       218\n",
      "dataRegion                 0\n",
      "areaName                   0\n",
      "areaDescription            0\n",
      "dtype: int64\n",
      "\n",
      "Class distribution of target variable:\n",
      "price_increased\n",
      "1    3798\n",
      "0     551\n",
      "Name: count, dtype: int64\n",
      "Percentage of price increases: 87.33%\n",
      "\n",
      "Using numeric features: ['periodYear', 'cpi']\n",
      "Using categorical features: ['areaType', 'periodType', 'type', 'dataRegion']\n",
      "\n",
      "Summary statistics for numerical features:\n",
      "        periodYear          cpi\n",
      "count  4349.000000  4349.000000\n",
      "mean   1970.362382    83.272986\n",
      "std      27.354856    73.970614\n",
      "min    1913.000000     9.700000\n",
      "25%    1951.000000    25.500000\n",
      "50%    1972.000000    42.400000\n",
      "75%    1994.000000   142.600000\n",
      "max    2014.000000   487.877000\n",
      "\n",
      "--- Decision Tree Classifier ---\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "\n",
      "Best hyperparameters for Decision Tree:\n",
      "{'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}\n",
      "\n",
      "Decision Tree Test Accuracy: 0.9655172413793104\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       110\n",
      "           1       0.98      0.98      0.98       760\n",
      "\n",
      "    accuracy                           0.97       870\n",
      "   macro avg       0.92      0.92      0.92       870\n",
      "weighted avg       0.97      0.97      0.97       870\n",
      "\n",
      "\n",
      "--- Logistic Regression ---\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Best hyperparameters for Logistic Regression:\n",
      "{'classifier__C': 0.001, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "\n",
      "Logistic Regression Test Accuracy: 0.8735632183908046\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       110\n",
      "           1       0.87      1.00      0.93       760\n",
      "\n",
      "    accuracy                           0.87       870\n",
      "   macro avg       0.44      0.50      0.47       870\n",
      "weighted avg       0.76      0.87      0.81       870\n",
      "\n",
      "\n",
      "Error in feature importance extraction: 'ColumnTransformer' object has no attribute 'transformers_'\n",
      "Continuing with analysis...\n",
      "\n",
      "Analysis complete! Models have been trained and evaluated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import plot_tree\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Downloads/denver_cpi.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumn dtypes:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Data preparation\n",
    "# Create the target variable based on percentChangeYear\n",
    "df['price_increased'] = df['percentChangeYear'] > 0\n",
    "\n",
    "# Filter out rows with NaN in percentChangeYear\n",
    "df = df.dropna(subset=['percentChangeYear'])\n",
    "\n",
    "# Convert target to numeric (0/1) for modeling\n",
    "df['price_increased'] = df['price_increased'].astype(int)\n",
    "\n",
    "# Display the class distribution\n",
    "print(\"\\nClass distribution of target variable:\")\n",
    "print(df['price_increased'].value_counts())\n",
    "print(f\"Percentage of price increases: {df['price_increased'].mean() * 100:.2f}%\")\n",
    "\n",
    "# Create feature matrix and target vector\n",
    "# Select numerical and categorical features that might be useful for prediction\n",
    "# Exclude features that leak information or are irrelevant\n",
    "numeric_features = ['periodYear', 'cpi']\n",
    "categorical_features = ['areaType', 'periodType', 'type', 'dataRegion']\n",
    "\n",
    "# Make sure all features exist in the dataset\n",
    "numeric_features = [col for col in numeric_features if col in df.columns]\n",
    "categorical_features = [col for col in categorical_features if col in df.columns]\n",
    "\n",
    "# Sanity check\n",
    "print(\"\\nUsing numeric features:\", numeric_features)\n",
    "print(\"Using categorical features:\", categorical_features)\n",
    "\n",
    "# Create feature matrix X and target vector y\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df['price_increased']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "print(\"\\nSummary statistics for numerical features:\")\n",
    "print(df[numeric_features].describe())\n",
    "\n",
    "# Plot the distribution of the target variable\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='price_increased', data=df)\n",
    "plt.title('Distribution of Price Increases')\n",
    "plt.xlabel('Price Increased (1=Yes, 0=No)')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('target_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot the relationship between periodYear and cpi\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='periodYear', y='cpi', data=df, hue='areaType')\n",
    "plt.title('CPI Trend Over Years by Area Type')\n",
    "plt.savefig('cpi_trend.png')\n",
    "plt.close()\n",
    "\n",
    "# Correlation analysis\n",
    "if len(df.select_dtypes(include=['float64', 'int64']).columns) > 0:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    numerical_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "    if 'price_increased' in numerical_df.columns:\n",
    "        correlation = numerical_df.corr()\n",
    "        sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "        plt.title('Correlation Matrix of Numerical Features')\n",
    "        plt.savefig('correlation_matrix.png')\n",
    "        plt.close()\n",
    "\n",
    "        print(\"\\nCorrelation with target variable:\")\n",
    "        print(correlation['price_increased'].sort_values(ascending=False))\n",
    "\n",
    "# 1. Decision Tree Model with Hyperparameter Tuning\n",
    "print(\"\\n--- Decision Tree Classifier ---\")\n",
    "\n",
    "# Create pipeline with preprocessing and model\n",
    "dt_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid\n",
    "dt_param_grid = {\n",
    "    'classifier__max_depth': [None, 5, 10, 15, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "dt_grid_search = GridSearchCV(\n",
    "    dt_pipeline, \n",
    "    dt_param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"\\nBest hyperparameters for Decision Tree:\")\n",
    "print(dt_grid_search.best_params_)\n",
    "\n",
    "# Evaluate on test set\n",
    "dt_best = dt_grid_search.best_estimator_\n",
    "dt_y_pred = dt_best.predict(X_test)\n",
    "\n",
    "print(\"\\nDecision Tree Test Accuracy:\", accuracy_score(y_test, dt_y_pred))\n",
    "print(\"\\nDecision Tree Classification Report:\")\n",
    "print(classification_report(y_test, dt_y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "dt_cm = confusion_matrix(y_test, dt_y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(dt_cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Increase', 'Increase'],\n",
    "            yticklabels=['No Increase', 'Increase'])\n",
    "plt.title('Decision Tree Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('dt_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Logistic Regression with Hyperparameter Tuning\n",
    "print(\"\\n--- Logistic Regression ---\")\n",
    "\n",
    "# Create pipeline with preprocessing and model\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid\n",
    "lr_param_grid = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "lr_grid_search = GridSearchCV(\n",
    "    lr_pipeline, \n",
    "    lr_param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"\\nBest hyperparameters for Logistic Regression:\")\n",
    "print(lr_grid_search.best_params_)\n",
    "\n",
    "# Evaluate on test set\n",
    "lr_best = lr_grid_search.best_estimator_\n",
    "lr_y_pred = lr_best.predict(X_test)\n",
    "\n",
    "print(\"\\nLogistic Regression Test Accuracy:\", accuracy_score(y_test, lr_y_pred))\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, lr_y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "lr_cm = confusion_matrix(y_test, lr_y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(lr_cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Increase', 'Increase'],\n",
    "            yticklabels=['No Increase', 'Increase'])\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('lr_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Compare models\n",
    "models = ['Decision Tree', 'Logistic Regression']\n",
    "accuracies = [accuracy_score(y_test, dt_y_pred), accuracy_score(y_test, lr_y_pred)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=models, y=accuracies)\n",
    "plt.title('Model Comparison - Test Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.savefig('model_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Feature importance for Decision Tree - FIXED CODE FOR FEATURE IMPORTANCE\n",
    "if hasattr(dt_best['classifier'], 'feature_importances_'):\n",
    "    # Get feature names after preprocessing\n",
    "    # Alternative approach for getting feature names\n",
    "    try:\n",
    "        # First, get the one-hot encoded feature names\n",
    "        cat_features = []\n",
    "        for feature in categorical_features:\n",
    "            # Apply the transformer to get categories\n",
    "            encoder = preprocessor.named_transformers_['cat']\n",
    "            if hasattr(encoder, 'get_feature_names_out'):\n",
    "                # For newer scikit-learn versions\n",
    "                encoded_features = encoder.get_feature_names_out([feature])\n",
    "                cat_features.extend(encoded_features)\n",
    "            else:\n",
    "                # For older versions\n",
    "                cat_features.extend([f\"{feature}_{i}\" for i in range(encoder.transform(X[[feature]].drop_duplicates()).shape[1])])\n",
    "        \n",
    "        # Combine with numeric features\n",
    "        all_features = numeric_features + cat_features\n",
    "        \n",
    "        # Get feature importances\n",
    "        feature_importances = dt_best['classifier'].feature_importances_\n",
    "        \n",
    "        # Create a simpler version that doesn't rely on exact feature names matching\n",
    "        # Just use indices and generic feature names\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': [f\"Feature_{i}\" for i in range(len(feature_importances))],\n",
    "            'Importance': feature_importances\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))\n",
    "        plt.title('Top 15 Feature Importances (Decision Tree)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('dt_feature_importance.png')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"\\nTop 10 most important features (by index):\")\n",
    "        print(importance_df.head(10))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in feature importance extraction: {e}\")\n",
    "        print(\"Continuing with analysis...\")\n",
    "\n",
    "print(\"\\nAnalysis complete! Models have been trained and evaluated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c324c7-b03d-4f92-b54e-863e05ba54a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
